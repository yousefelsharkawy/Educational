{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd3f2375",
   "metadata": {},
   "source": [
    "# neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06db8186",
   "metadata": {},
   "source": [
    "- started by the motivation to mimic the brain (how the neurons in it interact with each other)\n",
    "- despite being different than how the brain learns (we still don't have alot of knowledge in this field), yet it turned out to be powerful learning algorithm\n",
    "- became rebranded with **deep learning** and became in favour after the increase of data due to digitization of our world and the increase in GPUs performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c7ccab",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#MakePredictionswithTrainedNeuralNetwork\">1- Make Predictions with Trained Neural Network</a>\n",
    "    <ul>\n",
    "        <li><a href=\"#UsingTensorFlow\">1A. Using Tensor Flow</a>\n",
    "- first on a single neuron \n",
    "- then on whole neural network \n",
    "- then on a succent way of doing it </li>\n",
    "        <li><a href=\"#manually\">1B. manually</a></li>\n",
    "    </ul></li>\n",
    "    <li><a href=\"#training\">2.Training a neural network</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c023b67",
   "metadata": {},
   "source": [
    "<a id='MakePredictionswithTrainedNeuralNetwork'></a>\n",
    "## 1- Make predictions with trained neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4c53d9",
   "metadata": {},
   "source": [
    "- **inference** : making predictions with a trained neural network\n",
    "- also called **Forward propagation**, as we propagate the activations forward through the layers from the firt to the last"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ba50a8",
   "metadata": {},
   "source": [
    "<a id='UsingTensorFlow'></a>\n",
    "### 1A. using Tensor flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d2a2cf",
   "metadata": {},
   "source": [
    "**Tensorflow and Keras**  \n",
    "Tensorflow is a machine learning package developed by Google. In 2019, Google integrated Keras into Tensorflow and released Tensorflow 2.0. Keras is a framework developed independently by Fran√ßois Chollet that creates a simple, layer-centric interface to Tensorflow. This course will be using the Keras interface. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1514ba1",
   "metadata": {},
   "source": [
    "#### First with a single neauron!\n",
    "- we will notice that a single neuron is similar to the models we studied in course 1 \n",
    "    - linear regression\n",
    "    - logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f655c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy\n",
    "from tensorflow.keras.activations import sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384fcea4",
   "metadata": {},
   "source": [
    "## About tensor flow "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5daaad4",
   "metadata": {},
   "source": [
    "- **Dense**: The type of layers we are learning so far \n",
    "- **Activation function**: This is the model of the neuron, and they are called activation functions because they produce the activations \n",
    "    - we may have different kinds of activation functions but for now we use the sigmoid function as an activation function\n",
    "    - so with the sigmoid function , each neuron does logistic regression \n",
    "- The order of operations \n",
    "    1. it takes a number or multiple numbers\n",
    "    2. they do some calculations on them \n",
    "    3. they produce number of multiple numbers, that can be an input to another layer of neurons \n",
    "\n",
    "### Numpy and tensor flow integration\n",
    "- we usually load and manipulate the data using numpy arrays\n",
    "- but when we pass them to Tensor flow, we **Pass them as 2D numpy arrays** \n",
    "    - that is because Tensor Flow has its own data type (to operate efficeintly using it) **called Tensor** and the conversion can be done if it's 2D \n",
    "    - we can think of Tensor as a matrix (but it is more general than that)\n",
    "- TensorFlow hands back the rturned value as Tensor \n",
    "    - we may choose to keep it that way\n",
    "    - we may convert it back to numpy array using result.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f64e0f",
   "metadata": {},
   "source": [
    "### Regression/Linear Model \n",
    "The function implemented by a neuron with no activation is the same as in Course 1, linear regression:\n",
    "$$ f_{\\mathbf{w},b}(x^{(i)}) = \\mathbf{w}\\cdot x^{(i)} + b \\tag{1}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab149960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we will use the same data we used in Linear regression for Housing problem\n",
    "X_train = np.array([[1.0], [2.0]], dtype=np.float32)           #(size in 1000 square feet)\n",
    "Y_train = np.array([[300.0], [500.0]], dtype=np.float32)       #(price in 1000s of dollars)\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.scatter(X_train, Y_train, marker='x', c='r', label=\"Data Points\")\n",
    "ax.legend( fontsize='xx-large')\n",
    "ax.set_ylabel('Price (in 1000s of dollars)', fontsize='xx-large')\n",
    "ax.set_xlabel('Size (1000 sqft)', fontsize='xx-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16471a58",
   "metadata": {},
   "source": [
    "layer = tf.keras.layers.Dense(units = \"N\", activation = \" \")\n",
    "- here Dense creates a layer with **N** units/neurons and each one implement a certain activation function \n",
    "- the returned to layer which is actually a **function**\n",
    "    - if trained, we should have the parameter weights and load them to the layer \n",
    "    - we give it the input vector to the layer and it calculates the activation vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d66eacc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = tf.keras.layers.Dense(units = 1, activation = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28e41867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to retreive the weights\n",
    "linear_layer.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffde902",
   "metadata": {},
   "source": [
    "There are no weights as the weights are not yet instantiated. Let's try the model on one example in `X_train`. This will trigger the instantiation of the weights. Note, the input to the layer must be 2-D, so we'll reshape it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e0f2082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape #Xtrain as a whole is 2D but"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d9a6a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3446ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape #one example here is 1D of length 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc7fb6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].reshape(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3776c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.9627837]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = linear_layer(X_train[0].reshape(1,1))\n",
    "a1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7de97d8",
   "metadata": {},
   "source": [
    "The result is a tensor (another name for an array) with a shape of (1,1) or one entry.   \n",
    "Now let's look at the weights and bias. These weights are randomly initialized to small numbers and the bias defaults to being initialized to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c4935de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.9627837]], dtype=float32), array([0.], dtype=float32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = linear_layer.get_weights()\n",
    "w,b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab684409",
   "metadata": {},
   "source": [
    "- that's why we got the above random activation with the value of the randomly initialized w \n",
    "$$ a1 = w * (1) + 0 = w $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d76e04",
   "metadata": {},
   "source": [
    "A linear regression model (1) with a single input feature will have a single weight and bias. This matches the dimensions of our `linear_layer` above.   \n",
    "- that means the size of the parameters got adjusted to the data \n",
    "    - **x** was 1x1 (scalar) so w was inititlzed as scalar\n",
    "\n",
    "The weights are initialized to random values so let's set them to some known values. (load them with the correct parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0afe6be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the correct values to the neuron\n",
    "w = np.array([[200]])\n",
    "b = np.array([100]) #why scalar ? maybe because it is always scalar\n",
    "\n",
    "linear_layer.set_weights([w,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "398f3b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[200.]], dtype=float32), array([100.], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1e8d73",
   "metadata": {},
   "source": [
    "let's predict manually and using the neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6f0edc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual result:[300.], neuron result: [[300.]]\n"
     ]
    }
   ],
   "source": [
    "#manually \n",
    "y_prid0 = np.dot(X_train[0],w) + b\n",
    "#using the neuron \n",
    "y_prid = linear_layer(X_train[0].reshape(1,1))\n",
    "print(f\"manual result:{y_prid0}, neuron result: {y_prid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212bf759",
   "metadata": {},
   "source": [
    "They produce the same values!\n",
    "Now, we can use our linear layer to make predictions on our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9748137",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_tf = linear_layer(X_train)\n",
    "predictions_np = np.dot(X_train,w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78d68630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[300.],\n",
       "       [500.]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6967351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04654144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[300.],\n",
       "       [500.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1823dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303e63f1",
   "metadata": {},
   "source": [
    "## Neuron with Sigmoid activation\n",
    "The function implemented by a neuron/unit with a sigmoid activation is the same as in Course 1, logistic  regression:\n",
    "$$ f_{\\mathbf{w},b}(x^{(i)}) = g(\\mathbf{w}x^{(i)} + b) \\tag{2}$$\n",
    "where $$g(x) = sigmoid(x)$$ \n",
    "\n",
    "We'll use an example from Course 1, logistic regression.\n",
    "\n",
    "Let's set $w$ and $b$ to some known values and check the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9264fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([0., 1, 2, 3, 4, 5], dtype=np.float32).reshape(-1,1)  # 2-D Matrix\n",
    "Y_train = np.array([0,  0, 0, 1, 1, 1], dtype=np.float32).reshape(-1,1)  # 2-D Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e130dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos = Y_train == 1\n",
    "neg = Y_train == 0\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(4,3))\n",
    "ax.scatter(X_train[pos], Y_train[pos], marker='x', s=80, c = 'red', label=\"y=1\")\n",
    "ax.scatter(X_train[neg], Y_train[neg], marker='o', s=100, label=\"y=0\", c ='blue')\n",
    "\n",
    "ax.set_ylim(-0.08,1.1)\n",
    "ax.set_ylabel('y', fontsize=12)\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_title('one variable plot')\n",
    "ax.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a181c279",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_layer = Dense(1, activation = 'sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab21a210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e208fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.5]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_layer(X_train[0].reshape(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3e4f860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the correct parameters to the neuron\n",
    "set_w = np.array([[2]])\n",
    "set_b = np.array([-4.5])\n",
    "\n",
    "logistic_layer.set_weights([set_w,set_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56a818de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[2.]], dtype=float32), array([-4.5], dtype=float32)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_layer.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecfdd52",
   "metadata": {},
   "source": [
    "let's predict using the correct weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ed39fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 1), dtype=float32, numpy=\n",
       "array([[0.01098694],\n",
       "       [0.07585818],\n",
       "       [0.37754068],\n",
       "       [0.8175745 ],\n",
       "       [0.97068775],\n",
       "       [0.99592984]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = logistic_layer(X_train) \n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78d15359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9861921b",
   "metadata": {},
   "source": [
    "- These are the probabilities of the output being 1 (the activation values)\n",
    "    - we can get binary output (0 or 1) by applying theshold\n",
    "    - we will use 0.5 as threshold\n",
    "- note that this is 6 examples of 1x1 input x and it will produce 6 examples of 1x1 (because that seemed like it dipicts the saying that a single neuron produces a single activation -that is correct for a vector of single example-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3cb14f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01098694],\n",
       "       [0.07585818],\n",
       "       [0.37754068],\n",
       "       [0.8175745 ],\n",
       "       [0.97068775],\n",
       "       [0.99592984]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = a1.numpy()\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0febb0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = (a1 > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d75b5d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b10936",
   "metadata": {},
   "source": [
    "agrees with the correct labels y!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4de8dca",
   "metadata": {},
   "source": [
    "### Second with a whole network!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aed1ca2",
   "metadata": {},
   "source": [
    "<img  src=\"supplies/C2_W1_CoffeeRoasting.png\" width=\"400\" />\n",
    "\n",
    "we have a trained model on coffee data and we wanna use it to make **inference** (predictions) on new data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eadd6b9",
   "metadata": {},
   "source": [
    "## The model\n",
    "<center> <img  src=\"supplies/C2_W1_RoastingNetwork.PNG\" width=\"200\" />   <center/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480154d2",
   "metadata": {},
   "source": [
    "- the architecture is 2 layers \n",
    "    - input layer (input vector) of length 2 (per example)\n",
    "    - one hidden layer with 3 neurons \n",
    "    - one final layer (output) layer\n",
    "- since the input is of length 2 so for the first layer we have $w_{1}^{[1]}$ and $w_{2}^{[1]}$ and $w_{3}^{[1]}$ of length 2 each and b are scalars for all of them\n",
    "- since the output of the first layer (activations) $a^{[1]}$ is a vector of length 3 so the parameter of the output layer is $w_{1}^{[3]}$ is of length 3 and b as scalar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aaaa21a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained parameters\n",
    "W1 = np.array([\n",
    "    [-8.94,  0.29, 12.89],\n",
    "    [-0.17, -7.34, 10.79]] )\n",
    "b1 = np.array([-9.87, -9.28,  1.01])\n",
    "W2 = np.array([\n",
    "    [-31.38],\n",
    "    [-27.86],\n",
    "    [-32.79]])\n",
    "b2 = np.array([15.54])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4f3390",
   "metadata": {},
   "source": [
    "- W1 is the parameters of layer1\n",
    "    - each neuron's paramter is read vertically, so each column is w for a neuron\n",
    "    - and the vector length is spread horizontally \n",
    "- so here layer1 has 3 neurons each has parameter w of length 2\n",
    "    - so the matrix size is 2x3\n",
    "    \n",
    "Let's examine the weights and biases Tensorflow has instantiated.  The weights $W$ should be of size (number of features in input, number of units in the layer) while the bias $b$ size should match the number of units in the layer:\n",
    "- In the first layer with 3 units, we expect W to have a size of (2,3) and $b$ should have 3 elements.\n",
    "- In the second layer with 1 unit, we expect W to have a size of (3,1) and $b$ should have 1 element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec8d2a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the neural network layer by layer\n",
    "layer1 = Dense(units = 3, input_dim = 2, activation = 'sigmoid')\n",
    "layer2 = Dense(units = 1, activation = 'sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "607272a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([\n",
    "    [-0.47,0.42],  # postive example\n",
    "    [-0.47,3.16]])   # negative example\n",
    "# the new example here is after normalization because the original training data was normalized before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "046d0c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use an example to instantiate random weights before loading the correct ones, why?\n",
    "a1 = layer1(X_test[0].reshape(1,2))\n",
    "a2 = layer2(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "327aa22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1.set_weights([W1,b1])\n",
    "layer2.set_weights([W2,b2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b0b2e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-8.94,  0.29, 12.89],\n",
       "        [-0.17, -7.34, 10.79]], dtype=float32),\n",
       " array([-9.87, -9.28,  1.01], dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44296aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-31.38],\n",
       "        [-27.86],\n",
       "        [-32.79]], dtype=float32),\n",
       " array([15.54], dtype=float32)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be6b11f",
   "metadata": {},
   "source": [
    "you can then use the model now to make predictions. Recall that the output of our model is a probability. In this case, the probability of a good roast. To make a decision, one must apply the probability to a threshold. In this case, we will use 0.5\n",
    "\n",
    "- here we carry out prediction manualy ourselves (not practical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e508969",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[9.6032798e-01],\n",
       "       [3.0266833e-08]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = layer1(X_test)\n",
    "a2 = layer2(a1)\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c3594400",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply threshold (at 0.5) to make it 0 or 1\n",
    "result = a2.numpy()\n",
    "(result >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a00d28e",
   "metadata": {},
   "source": [
    "### succent way of doing it  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b62dab",
   "metadata": {},
   "source": [
    "- we used to explicitly carry out forward propagation (prediction) ourselves in the previous way \n",
    "- it turns out there is a different way of modeling and building a neural network\n",
    "    - makes it easier to predict (do forward propagation), and also make it easier in learning! (we will see later)\n",
    "- we will do that using the **sequential** function\n",
    "    - it takes the layers and string them together to make a neural network\n",
    "    - learning will be only using 2 functions!\n",
    "        - compile(...) \n",
    "        - fit(Xtrain,ytrain)\n",
    "    - inference or forward propagation can be done with only 1 function\n",
    "        - predict(Xnew): carries out forward propagation provided the input to the whole network that we compiled using the sequentail function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "772d3597",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "[\n",
    "    tf.keras.Input(shape=(2,)), #for previously decide the size of the parameters (each record x is vector of length 2) so the parameters will be W (vector of length 2) and b (always scalar), otherwise it will be automatically adjusted on the given size during training\n",
    "    Dense(units = 3, activation = 'sigmoid',name='layer1'),\n",
    "    Dense(units = 1, activation = 'sigmoid',name='layer2')\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad4474d",
   "metadata": {},
   "source": [
    ">**Note 1:** The `tf.keras.Input(shape=(2,)),` specifies the expected shape of the input. This allows Tensorflow to size the weights and bias parameters at this point.  This is useful when exploring Tensorflow models. This statement can be omitted in practice and Tensorflow will size the network parameters when the input data is specified in the `model.fit` statement.  \n",
    ">**Note 2:** Including the sigmoid activation in the final layer is **not** considered best practice. It would instead be accounted for in the loss which improves numerical stability. This will be described in more detail in a later lab.\n",
    "\n",
    "The `model.summary()` provides a description of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebcaa73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, 3)                 9         \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13\n",
      "Trainable params: 13\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a35090",
   "metadata": {},
   "source": [
    "- the first layer outputs a vetor of length 3, has 9 parameters\n",
    "    - w of size 2 + b that's 3 paramteres per neuron \n",
    "    - 3 * 3 neurons that's 9 parameters total\n",
    "- for layer 2 it outputs vector of length 1 and has 4 parameters\n",
    "    - vector w of length 3 and b that's 4 total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01cd739f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layer 1 it has w(2, 3): [[ 0.65625525 -0.25639182  0.65546405]\n",
      " [ 0.71819067  0.22940159 -0.02074826]] and b(3,): [0. 0. 0.]\n",
      "For layer 2 it has w(3, 1): [[-0.68853444]\n",
      " [-0.29041433]\n",
      " [-0.5079181 ]] and b(1,): [0.]\n"
     ]
    }
   ],
   "source": [
    "# print the instantiated parametrs \n",
    "w1,b1 = model.get_layer(\"layer1\").get_weights()\n",
    "w2,b2 = model.get_layer(\"layer2\").get_weights()\n",
    "print(f\"For layer 1 it has w{w1.shape}: {w1} and b{b1.shape}: {b1}\")\n",
    "print(f\"For layer 2 it has w{w2.shape}: {w2} and b{b2.shape}: {b2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f919a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the correct parameters\n",
    "W1 = np.array([\n",
    "    [-8.94,  0.29, 12.89],\n",
    "    [-0.17, -7.34, 10.79]] )\n",
    "b1 = np.array([-9.87, -9.28,  1.01])\n",
    "W2 = np.array([\n",
    "    [-31.38],\n",
    "    [-27.86],\n",
    "    [-32.79]])\n",
    "b2 = np.array([15.54])\n",
    "model.get_layer('layer1').set_weights([W1,b1])\n",
    "model.get_layer('layer2').set_weights([W2,b2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1743cff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-8.94,  0.29, 12.89],\n",
       "        [-0.17, -7.34, 10.79]], dtype=float32),\n",
       " array([-9.87, -9.28,  1.01], dtype=float32)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('layer1').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5804c04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-31.38],\n",
       "        [-27.86],\n",
       "        [-32.79]], dtype=float32),\n",
       " array([15.54], dtype=float32)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('layer2').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ad32580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict now with Xnew\n",
    "X_test = np.array([\n",
    "    [-0.47,0.42],  # postive example\n",
    "    [-0.47,3.16]])   # negative example\n",
    "# the new example here is after normalization because the original training data was normalized before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "984b8e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.6032798e-01],\n",
       "       [3.0266833e-08]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c12f719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [False]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply threshold on the predictions (probabilities)\n",
    "mask = (predictions >= 0.5)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb985b8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a117e10",
   "metadata": {},
   "source": [
    "<a id=\"manually\"></a>\n",
    "## 1B. Carry out predictions manually\n",
    "- we will define a function my dense \n",
    "    - it calculates carries out the calculations for a layer \n",
    "    - it takes the input vector to a layer and parameters of the layer then outputs the output vector of that layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd3e3ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "903485b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_dense(a_in, W, b, g): #correct\n",
    "    \"\"\"\n",
    "    Computes dense layer\n",
    "    Args:\n",
    "      a_in (ndarray (n, )) : Data, 1 example \n",
    "      W    (ndarray (n,j)) : Weight matrix, n features per unit, j units\n",
    "      b    (ndarray (j, )) : bias vector, j units  (vector because tf utilizes b as vector)\n",
    "    Returns\n",
    "      a_out (ndarray (j,))  : j units|\n",
    "    \"\"\"\n",
    "    neurons = b.shape[0]\n",
    "    a_out = np.zeros(neurons)\n",
    "    for j in range(neurons):\n",
    "        w = W[:,j] # each loop we take a column (parameter of ith neuron)\n",
    "        z = np.dot(w,a_in) + b[j]\n",
    "        a_out[j] = g(z)\n",
    "    return a_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe2f880",
   "metadata": {},
   "source": [
    "utilize `my_dense` function to make a neural network for coffee roast (we can do that for any number of layers in any network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87617896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential(x,W1,b1,W2,b2,activation):\n",
    "    a1 = my_dense(x,W1,b1,activation)\n",
    "    a2 = my_dense(a1,W2,b2,activation)\n",
    "    return a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9e19a0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96032792])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's do the forward propagation we made on a new example\n",
    "X_test = np.array([-0.47,0.42])\n",
    "a2 = sequential(X_test,W1,b1,W2,b2,sigmoid)\n",
    "a2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab69464",
   "metadata": {},
   "source": [
    "Let's start by writing a routine similar to Tensorflow's `model.predict()`. This will take a matrix $X$ with all $m$ examples in the rows and make a prediction by running the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41ac1d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_predict(X,W1,b1,W2,b2,activation):\n",
    "    m = X.shape[0]\n",
    "    predictions = np.zeros((m,1)) #why 2D?\n",
    "    for i in range(m):\n",
    "        predictions[i] = sequential(X[i],W1,b1,W2,b2,activation) # this is what we did above for one example\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e84fbc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([\n",
    "    [-0.47,0.42],  # postive example\n",
    "    [-0.47,3.16]])   # negative example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d15e2851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.60327924e-01],\n",
       "       [3.02668433e-08]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = my_predict(X_test,W1,b1,W2,b2,sigmoid)\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5311240c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a2 >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe704f2",
   "metadata": {},
   "source": [
    "## Vectorized implementation of forward propagation (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b648d4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_dense_vect(a_in, W, b, g):\n",
    "     \"\"\"\n",
    "    Computes dense layer\n",
    "    Args:\n",
    "      A_in (ndarray (m,n)) : Data, m examples, n features each\n",
    "      W    (ndarray (n,j)) : Weight matrix, n features per unit, j units\n",
    "      b    (ndarray (1,j)) : bias vector, j units  \n",
    "      g    activation function (e.g. sigmoid, relu..)\n",
    "    Returns\n",
    "      A_out (ndarray (m,j)) : m examples, j units\n",
    "    \"\"\"\n",
    "    Z = np.matmul(a_in,W) + b\n",
    "    a_out = g(Z)\n",
    "    return a_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d348ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_vect(x,W1,b1,W2,b2,activation): # the same but here we call the vectorized layer implementation\n",
    "    a1 = my_dense_vect(x,W1,b1,activation)\n",
    "    a2 = my_dense_vect(a1,W2,b2,activation)\n",
    "    return a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ea5648ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96032792]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's do the forward propagation we made on a new example\n",
    "X_test = np.array([[-0.47,0.42]]) # now we make sure it is row vector (1x2 mul W1 which is here 2x3)\n",
    "a2 = sequential_vect(X_test,W1,b1,W2,b2,sigmoid)\n",
    "a2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4301ddb",
   "metadata": {},
   "source": [
    " `my_dense_vect` can also handle multiple examples! so no need to use something like `my_predict` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b8453b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([\n",
    "    [-0.47,0.42],  # postive example\n",
    "    [-0.47,3.16]])   # negative example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bbd1fab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.60327924e-01],\n",
       "       [3.02668433e-08]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = my_predict(X_test,W1,b1,W2,b2,sigmoid)\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "da04254e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a2 >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1919697",
   "metadata": {},
   "source": [
    "matrix multiplication will work as long as we follow the convention of the input and writing W matrix for each layer in the right way mentioned above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4993d20f",
   "metadata": {},
   "source": [
    "<a id=\"training\"></a>\n",
    "# Training a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00989e9",
   "metadata": {},
   "source": [
    "- we will look at training a neural network in Tensor flow \n",
    "there are 3 steps to do that \n",
    "1. create the model (create the neural network and this correspondes to **creating the equation of $\\hat{y}$** given x and the parameters) and this includes \n",
    "- specifying the architecture of the model \n",
    "    - the number of layers \n",
    "    - the units in each layer \n",
    "- specifying the units activation functions\n",
    "    - for the output layer we naturally have systematic choices \n",
    "        - if we are doing **binary classification problem** then we use **sigmoid** activation function with one unit\n",
    "        - for **multicalss classification** we use **softmax acticvation functions** with number of neurons like the number of classes or categories that the value of y can take \n",
    "        - if we are doing **regression problem**:\n",
    "            - if y can be +ve and -ve (ex. stocks) we use **linear** activation function \n",
    "            - if y can only be +ve or 0 (non-negative) like housing problems then we use **Relu**\n",
    "    - for the **hidden** layers we use **Relu**\n",
    "2. compile the model, correspondes to **specifying the loss function** and this includes:\n",
    "- specifying the loss (therefor specifying the cost function as it is the average of all losses for all examples)\n",
    "3. fit the data **run gradient descent to minimize the algorithm**\n",
    "- give it the data and number of **epochs**: how many times we want the learning algorithm -like GD- to run\n",
    "- what it does is using backward propagation to calculate the partial derivatives (for every element in each w in each neuron in each layer and also the b for each neuron for each layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eaea83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f32a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7497825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5140a3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c8fbc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110f9d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99daa4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee35e0de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1d5ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e6bf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('supplies/test.npy', 'rb') as f:\n",
    "    X = np.load(f) # X is the temprature in celecius, And duration in minutes \n",
    "    Y = np.load(f) # Y is the label good coffee?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ddefab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:5],Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5a654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0515473",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:,0].max(),X[:,0].mean(),X[:,0].min() # The temprature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab13e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:,1].max(),X[:,1].mean(),X[:,1].min() # the duration column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaf45a2",
   "metadata": {},
   "source": [
    "### Tip: Normalize Data\n",
    "Fitting the weights to the data (back-propagation, covered in next week's lectures) will proceed more quickly if the data is normalized. This is the same procedure you used in Course 1 where features in the data are each normalized to have a similar range. \n",
    "The procedure below uses a Keras [normalization layer](https://keras.io/api/layers/preprocessing_layers/numerical/normalization/). It has the following steps:\n",
    "- create a \"Normalization Layer\". Note, as applied here, this is not a layer in your model.\n",
    "- 'adapt' the data. This learns the mean and variance of the data set and saves the values internally.\n",
    "- normalize the data.  \n",
    "It is important to apply normalization to any future data that utilizes the learned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f51cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Normalization(axis = -1)\n",
    "normalization_layer.adapt(X) #learns mean and variance\n",
    "Xn = normalization_layer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955afe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn = Xn.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54554043",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn[:,0].max(),Xn[:,0].mean(),Xn[:,0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb43717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn[:,1].max(),Xn[:,1].mean(),Xn[:,1].min()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
