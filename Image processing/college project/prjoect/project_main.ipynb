{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b2ff18a",
   "metadata": {},
   "source": [
    "## Relevent imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dca9382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant imports \n",
    "import numpy as np\n",
    "import cv2\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1808d9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.VideoWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0284fa",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80b3ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_transform(img): # first one\n",
    "    # Get the image x and y dimensions, will be used in the destination points\n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "    # Identify the source points \n",
    "    src = np.float32([[510,460], [750,460],[150,650],[1200,650]])\n",
    "    #identify the destination points \n",
    "    offset = 150\n",
    "    dst = np.float32([[offset, offset], [img_size[0]-offset, offset], \n",
    "                                     [offset, img_size[1]-offset],\n",
    "                                     [img_size[0]-offset, img_size[1]-offset] \n",
    "                                    ])\n",
    "    # Get the transformation matrix necissary for mapping\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    # Get the inverse matrix to transform the image back\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    # wrap the image\n",
    "    warped = cv2.warpPerspective(img, M, img_size)\n",
    "    return warped, M, Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf524de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_transform(img): # recent\n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "    #src = np.float32([[540,424], [500,900],[650,150],[650,1200]])\n",
    "    src = np.float32([[424,540], [900,500],[150,650],[1200,650]])\n",
    "    offset = 0\n",
    "    \n",
    "    dst = np.float32([[offset, offset], [img_size[0]-offset, offset], \n",
    "                                     [offset, img_size[1]-offset],\n",
    "                                     [img_size[0]-offset, img_size[1]-offset] \n",
    "                                    ])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    warped = cv2.warpPerspective(img, M, img_size)\n",
    "    return warped, M, Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "305cf7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_transform(img): # middle\n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "    src = np.float32([[545, 480],[735, 480],\n",
    "                      [310, 640],[990, 640]])\n",
    "    dst = np.float32([[310, 350], [1075, 350], \n",
    "                     [310, 640],[1075, 640]])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    warped = cv2.warpPerspective(img, M, img_size)\n",
    "    return warped, M, Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8173068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(img,M):\n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "    warped = cv2.warpPerspective(img, M, img_size)\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44e1bea",
   "metadata": {},
   "source": [
    "## Thresholding techs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85d7c034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def S_thresholder(S, thresh=(0, 255)):\n",
    "\n",
    "    S_threshold = S * 0\n",
    "    S_threshold[(S >= thresh[0]) & (S <= thresh[1])] = 1\n",
    "\n",
    "    return S_threshold\n",
    "\n",
    "\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    if orient == \"x\":\n",
    "        sobel = cv.Sobel(img, cv.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    elif orient == \"y\":\n",
    "        sobel = cv.Sobel(img, cv.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "\n",
    "    abs_sobel = np.abs(sobel)\n",
    "\n",
    "    scaled_sobel = np.uint8(255 * abs_sobel / np.max(abs_sobel))\n",
    "\n",
    "    sbinary = scaled_sobel * 0\n",
    "    sbinary[(scaled_sobel >= thresh[0]) & (scaled_sobel < thresh[1])] = 1\n",
    "\n",
    "    return sbinary\n",
    "\n",
    "\n",
    "# bad one\n",
    "def binarization_choice1(img):\n",
    "    S = cv.cvtColor(img, cv.COLOR_BGR2HLS)[:, :, 2]\n",
    "\n",
    "    sthresh = S_thresholder(S, (90, 255)) * 255\n",
    "    canny = cv.Canny(cv.GaussianBlur(S, (5, 5), 0), 50, 170)\n",
    "\n",
    "    binary_sobx_Sthreshs = S * 0\n",
    "    binary_sobx_Sthreshs[(sthresh == 255) | (canny == 255)] = 255\n",
    "\n",
    "    return binary_sobx_Sthreshs\n",
    "\n",
    "\n",
    "def BGR_equlization(frame, B=255, G=255, R=255):\n",
    "    B_eq = np.uint8(cv.equalizeHist(frame[:, :, 0]) * (B / 255))\n",
    "    G_eq = np.uint8(cv.equalizeHist(frame[:, :, 1]) * (G / 255))\n",
    "    R_eq = np.uint8(cv.equalizeHist(frame[:, :, 2]) * (R / 255))\n",
    "\n",
    "    return cv.merge((B_eq, G_eq, R_eq))\n",
    "\n",
    "\n",
    "def HLS_equlization(frame, H=255, L=255, S=255):\n",
    "    frame = cv.cvtColor(frame, cv.COLOR_BGR2HLS)\n",
    "    H_eq = np.uint8(cv.equalizeHist(frame[:, :, 0]) * (H / 255))\n",
    "    L_eq = np.uint8(cv.equalizeHist(frame[:, :, 1]) * (L / 255))\n",
    "    S_eq = np.uint8(cv.equalizeHist(frame[:, :, 2]) * (S / 255))\n",
    "\n",
    "    return cv.cvtColor(cv.merge((H_eq, L_eq, S_eq)), cv.COLOR_HLS2BGR)\n",
    "\n",
    "\n",
    "# current\n",
    "def binarization_choice2(frame):\n",
    "    frame_equlized_HLS = HLS_equlization(frame, 100, 50, 255)\n",
    "\n",
    "    S = cv.cvtColor(frame_equlized_HLS, cv.COLOR_BGR2HLS)[:, :, 2]\n",
    "\n",
    "    sthresh = S_thresholder(S, (140, 230)) * 255\n",
    "\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    canny = cv.Canny(gray, 40, 80)\n",
    "\n",
    "    gaussian = cv.GaussianBlur(gray, (9, 9), 0)\n",
    "    sobelx = abs_sobel_thresh(gaussian, \"x\", 3, (40, 220)) * 255\n",
    "\n",
    "    sobelx[canny == 255] = 0\n",
    "    sobelx = cv.dilate(sobelx, (15, 15))\n",
    "\n",
    "    binary = S * 0\n",
    "    binary[(sthresh == 255) | (sobelx == 255)] = 255\n",
    "\n",
    "    closing = cv.morphologyEx(binary, cv.MORPH_CLOSE, np.ones((7, 7)))\n",
    "\n",
    "    return closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d38f5e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobel_thresh1(img, orient='x', thresh_min=0, thresh_max=255,fullimage = True):\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    if fullimage:\n",
    "        grey = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        grey = img\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if orient == 'x':\n",
    "        # Here dx = 1 and dy = 0\n",
    "        gradient = cv2.Sobel(grey,cv2.CV_64F,1,0)\n",
    "    elif orient == 'y':\n",
    "        # Here dx = 0 and dy = 1\n",
    "        gradient = cv2.Sobel(grey,cv2.CV_64F,0,1)\n",
    "    # For the gradient, the range of output will be from -4*255 to 4*255\n",
    "    # 3) Take the absolute value of the derivative or gradient, now the range will be from 0 to 4*255\n",
    "    gradient_abs = abs(gradient)\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_gradient_abs = np.uint8(255*gradient_abs/gradient_abs.max()) #if maximum is 4*255 it will be like dividing by 4\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    binary_img = np.zeros_like(scaled_gradient_abs)\n",
    "    binary_img[(scaled_gradient_abs >= thresh_min) & (scaled_gradient_abs <= thresh_max)] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    #binary_output = np.copy(img) # Remove this line\n",
    "    return binary_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "621819cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_threshold(img, sobel_kernel=3, thresh=(0.85, 1.05)):\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c28a7fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(image):\n",
    "    output_sobelx = abs_sobel_thresh1(image, orient='x', thresh_min=20, thresh_max=100)\n",
    "    output_sobely = abs_sobel_thresh1(image, orient='y', thresh_min=20, thresh_max=100)\n",
    "    output_dir = dir_threshold(image, sobel_kernel=5, thresh=(0.8, 1.3))\n",
    "    hsv = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "    s_hsv = hsv[:,:,1]\n",
    "    h_hsv = hsv[:,:,0]\n",
    "    v_hsv = hsv[:,:,2]\n",
    "    \n",
    "    combined = np.zeros_like(s_hsv)\n",
    "    edge_mask = (output_sobely == 1) | (output_sobelx == 1) & (output_dir == 1)\n",
    "    mask = (s_hsv >= 60)\n",
    "    mask_unwanted = (v_hsv <= 60)\n",
    "    combined[edge_mask] = 1\n",
    "    combined[mask] = 1\n",
    "    combined[mask_unwanted] = 0\n",
    "    return combined "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e20de1f",
   "metadata": {},
   "source": [
    "## Lane detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5586f615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint #argmax returns the index of the max number (vertical sum) of the bottom half image \n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 50\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero() # return the indicies of the elements that are non zero, on the x and on the y\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window #\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # good left indicies are the non zero indicies inside the left window\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds) # left lane indicies are the good left indicies for all windows\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "    #print(left_lane_inds)\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "\n",
    "def fit_polynomial(binary_warped):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "\n",
    "    # Fit a second order polynomial to each using `np.polyfit`\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    #print(binary_warped.shape)\n",
    "    #print(ploty)\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    #plt.plot(left_fitx, ploty, color='yellow')\n",
    "    #plt.plot(right_fitx, ploty, color='yellow')\n",
    "    for i in range(1,left_fitx.shape[0]):\n",
    "        cv.line(out_img,(int(left_fitx[i-1]),int(ploty[i-1])),(int(left_fitx[i]),int(ploty[i])),(0,255,255),thickness = 3)\n",
    "        cv.line(out_img,(int(right_fitx[i-1]),int(ploty[i-1])),(int(right_fitx[i]),int(ploty[i])),(0,255,255),thickness = 3)\n",
    "    return out_img,left_fit,right_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fa6979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_poly(img_shape, leftx, lefty, rightx, righty,left_fit,right_fit):\n",
    "     ### TO-DO: Fit a second order polynomial to each with np.polyfit() ###\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    ### TO-DO: Calc both polynomials using ploty, left_fit and right_fit ###\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    return left_fitx, right_fitx, ploty\n",
    "\n",
    "def search_around_poly(binary_warped,left_fit,right_fit):\n",
    "    # HYPERPARAMETER\n",
    "    # Choose the width of the margin around the previous polynomial to search\n",
    "    # The quiz grader expects 100 here, but feel free to tune on your own!\n",
    "    margin = 50\n",
    "\n",
    "    # Grab activated pixels both on x axis and on y \n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    ### TO-DO: Set the area of search based on activated x-values ###\n",
    "    ### within the +/- margin of our polynomial function ###\n",
    "    ### Hint: consider the window areas for the similarly named variables ###\n",
    "    ### in the previous quiz, but change the windows to our new search area ###\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                    left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                    right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    # good left indicies are the non zero indicies inside the defined area\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit new polynomials\n",
    "    left_fitx, right_fitx, ploty = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty,left_fit,right_fit)\n",
    "    \n",
    "    ## Visualization ##\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                              ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                              ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    \n",
    "    # Plot the polynomial lines onto the image\n",
    "    #plt.plot(left_fitx, ploty, color='yellow')\n",
    "    #plt.plot(right_fitx, ploty, color='yellow')\n",
    "    ## End visualization steps ##\n",
    "    for i in range(1,left_fitx.shape[0]):\n",
    "        cv.line(result,(int(left_fitx[i-1]),int(ploty[i-1])),(int(left_fitx[i]),int(ploty[i])),(0,255,255),thickness = 3)\n",
    "        cv.line(result,(int(right_fitx[i-1]),int(ploty[i-1])),(int(right_fitx[i]),int(ploty[i])),(0,255,255),thickness = 3)\n",
    "    \n",
    "    return result,left_fit,right_fit,ploty\n",
    "\n",
    "# Run image through the pipeline\n",
    "# Note that in your project, you'll also want to feed in the previous fits\n",
    "#result = search_around_poly(binary_warped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591de951",
   "metadata": {},
   "source": [
    "## Drawing relevant info on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d03c84e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangle(image,left_eqn,right_eqn):\n",
    "    line_image = np.copy(image)*0 # creating a blank to draw lines on\n",
    "    #ploty = np.linspace(0, image.shape[0]-1, image.shape[0])\n",
    "    XX, YY = np.meshgrid(np.arange(0, image.shape[1]), np.arange(0, image.shape[0]))\n",
    "    region_thresholds = (XX < (right_eqn[0]*YY**2 + right_eqn[1]*YY + right_eqn[2])) & \\\n",
    "                        (XX > (left_eqn[0]*YY**2 + left_eqn[1]*YY + left_eqn[2])) #& \\\n",
    "                        #(YY < (right_eqn[0]*YY**2 + right_eqn[1]*YY + right_eqn[2])) & \\\n",
    "                        #(YY > (left_eqn[0]*YY**2 + left_eqn[1]*YY + left_eqn[2])) \n",
    "\n",
    "    line_image[region_thresholds] = (0xb9,0xff,0x99) #dcffcc\n",
    "    return line_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71f7e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_curvature_pixels(left_fit, right_fit):\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    y_eval = 720   # bottom of image\n",
    "    \n",
    "    # Calculation of R_curve (radius of curvature)\n",
    "    left_curverad  = ((1 + (2*(left_fit[0]/xm_per_pix)*y_eval*ym_per_pix + left_fit[1])**2)**1.5) / np.absolute(2*(left_fit[0]/xm_per_pix))\n",
    "    right_curverad = ((1 + (2*(right_fit[0]/xm_per_pix)*y_eval*ym_per_pix + right_fit[1])**2)**1.5) / np.absolute(2*(right_fit[0]/xm_per_pix))\n",
    "    \n",
    "    \n",
    "    ave_curvature = (left_curverad + right_curverad) / 2\n",
    "    \n",
    "    return ave_curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be882823",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply the function on videos \n",
    "capture = cv2.VideoCapture('project_video.mp4') #capture is instance of the videocapture class that contains the video given\n",
    "\n",
    "isTrue,frame = capture.read()\n",
    "output = binarization_choice2(frame)\n",
    "#output = threshold(frame)\n",
    "warped, m, minv = per_transform(output)\n",
    "first_time,left_eqn,right_eqn = fit_polynomial(warped)\n",
    "rectangle = draw_rectangle(frame,left_eqn,right_eqn)\n",
    "while True:\n",
    "    isTrue,frame = capture.read()\n",
    "    output = binarization_choice2(frame)\n",
    "    #output = threshold(frame)\n",
    "    warped = transform(output,m)\n",
    "    \n",
    "    output,left_eqn,right_eqn,ploty = search_around_poly(warped,left_eqn,right_eqn)\n",
    "    curve = measure_curvature_pixels(left_eqn,right_eqn)\n",
    "    #first_time,left_eqn,right_eqn = fit_polynomial(warped)\n",
    "    rectangle = draw_rectangle(frame,left_eqn,right_eqn)\n",
    "    transformed_back = transform(output,minv)\n",
    "    #correct_rectangle = transform(rectangle,minv)\n",
    "    cv.putText(frame,\"curvature: {} m\".format(curve),(255,255), cv.FONT_ITALIC,1.0,(255,255,255),2)\n",
    "    cv2.imshow('Video',cv.addWeighted(transformed_back,0.5,frame,1,0))\n",
    "    #cv2.imshow('Video',output*255)\n",
    "    if cv2.waitKey(16) & 0xFF == ord('q'): \n",
    "        break\n",
    "capture.release()  \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab27a576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function on videos \n",
    "capture = cv2.VideoCapture('challenge_video.mp4') #capture is instance of the videocapture class that contains the video given\n",
    "\n",
    "while True:\n",
    "    isTrue,frame = capture.read()\n",
    "    \n",
    "    #cv2.imshow('Video',output)\n",
    "    if cv2.waitKey(16) & 0xFF == ord('q'): \n",
    "        break\n",
    "capture.release()  \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13ffcb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29227564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
