{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP: Becoming a backprop Ninja\n",
    "\n",
    "- we will stick with mlp one more lecture, we have a pretty decent understanding of the architecture and how it works (forward pass)\n",
    "    - but we need to have a better understanding of the backward pass as well\n",
    "    - so, we will remove the use of loss.backward() -that uses pytorch's autograd- and implement it ourselves on the level of tensors\n",
    "- understanding the backward pass is important because it doesn't just make the network learn magically, we might shoot ourselves in the foot if we don't understand its internals\n",
    "    - we have to understand how it works under the hood if we are hoping to debug it and address it in the neural network\n",
    "\n",
    "- we took some examples\n",
    "    - like the flat tails of the activation functions and how they make gradients to be 0s, and therefore we don't want the logits to be saturated too much (based on our understanding of the backward pass, we addressed the issue)\n",
    "    - the case of dead neurons (when the gradients are 0s for all the examples)\n",
    "    - the case of exploding and vanishing gradients\n",
    "\n",
    "\n",
    "- `just because pytorch and other frameworks offer autograd, it doesn't mean that it is okay for us to ignore how it works`\n",
    "\n",
    "- benefit we get from understanding backprop\n",
    "    - it is a good exercise\n",
    "    - we will become better at debugging neural networks, and making sure we understand what we do\n",
    "    - will make everything fully explicit, and we won't be nervous about the black box of autograd\n",
    "\n",
    "- people in the past used to write the vectorized forward prop by hand then write the vectorized backward prop by hand as well, then use a gradient checking (numerical gradient checking) to make sure that the backward pass is correct\n",
    "    - just like what i did in neural networks from scratch\n",
    "- but today, people just use autograd and don't bother with the backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('makemore/names.txt').read().splitlines()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 0: '.'}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the vocabulary\n",
    "vocab = sorted(list(set(''.join(words))))\n",
    "stoi = { ch: i+1 for i, ch in enumerate(vocab) }\n",
    "stoi['.'] = 0\n",
    "itos = { i: ch for ch, i in stoi.items() }\n",
    "vocab_size = len(stoi)\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the dataset (mine: numericalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "block_size = 3\n",
    "def build_dataset(words):\n",
    "    #block_size = 4 # context length: how many characters do we take to predict the next one\n",
    "    Y, X = [], []\n",
    "    for word in words:\n",
    "        #print(word)\n",
    "        context = ['.'] * block_size  + list(word) + ['.']\n",
    "        for i in range(len(word) + 1):\n",
    "            X.append([stoi[ch] for ch in context[i:i+block_size]]) # append at index i, i+1, i+2 (i+3 is the label, that is why it is excluded here)\n",
    "            Y.append(stoi[context[i+block_size]]) # append the character i+3 as the label\n",
    "            #print(''.join(context[i:i+block_size]), '->', context[i+block_size])\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "# shuffle the words\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "\n",
    "x_train, y_train = build_dataset(words[:n1])\n",
    "x_val, y_val = build_dataset(words[n1:n2])\n",
    "x_test, y_test = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will be used to compare manual gradient to pytorch's autograd\n",
    "def cmp(s,dt,t):\n",
    "    \"\"\"\n",
    "    s: the name of the variable\n",
    "    dt: the result gradient of our manual backprop\n",
    "    t: the tensor in pytorch, which we will access t.grad to get pytorch's backprop gradient\n",
    "    \"\"\"\n",
    "    ex = torch.all(dt == t.grad).item()  # check if they are exatly equal\n",
    "    app = torch.allclose(dt, t.grad) # check if they are approximately equal, in case of floating point issues\n",
    "    maxdiff = (dt - t.grad).abs().max().item() # check the maximum different\n",
    "    print(f'{s:15s}: Exact: {str(ex):5s}, Approx: {str(app):5s}, Max diff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The architecture and training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embed = 10\n",
    "n_hidden = 64\n",
    "vocab_size = len(stoi)\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((vocab_size, n_embed),             generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embed * block_size, n_hidden), generator=g) * (5/3)/((n_embed * block_size) ** 0.5)\n",
    "B1 = torch.randn((1,n_hidden),                         generator=g) * 0.1 # just for fun, it is useless because of batch norm\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),           generator=g) * 0.1 # make the neural network unconfident\n",
    "B2 = torch.randn(vocab_size,                       generator=g) * 0.1 \n",
    "# Batch norm parameters\n",
    "gamma = torch.randn((1, n_hidden),                 generator=g)\n",
    "beta = torch.randn((1, n_hidden),                  generator=g)\n",
    "\n",
    "\n",
    "parameters = [C, W1, B1, W2, B2, gamma, beta]\n",
    "print(sum(p.numel() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we changed the initialization a little bit\n",
    "    - the bs were multiplied with small numbers (0.1) instead of making them 0s (we did this to expose any incorrect backpropagation implementation)\n",
    "    - we used b1 despite using batchnorm (just to make sure we can canculate the gradient for it correctly)\n",
    "    - mine: he should have divided W2 by the sqrt of the number of neurons in the previous layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "m = batch_size # a shorter variable for convenience\n",
    "\n",
    "idx = torch.randint(0, len(x_train), (batch_size,), generator=g)\n",
    "x_batch = x_train[idx]\n",
    "y_batch = y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.Size([32]))"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch.shape, y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = C[x_batch] # shape (m, block_size, n_embed)\n",
    "embcat = emb.view(m, -1) # shape (m, block_size * n_embed)\n",
    "# Linear layer 1\n",
    "z1 = embcat @ W1 + B1 # shape (m, n_hidden)\n",
    "# Batch norm\n",
    "z1_mean_i = 1/m * z1.sum(dim=0, keepdim=True) # mean = sum(x) / n, shape (1, n_hidden)\n",
    "diff = z1 - z1_mean_i # x - mean, shape (m, n_hidden)\n",
    "diff_sq = diff ** 2 # (x - mean) ** 2, shape (m, n_hidden)\n",
    "z1_var_i = 1/(m-1) * diff_sq.sum(dim=0,keepdim=True) # var = sum((x - mean) ** 2) / (n-1), we used n-1 which is bassel's correction, shape (1, n_hidden)\n",
    "z1_std_i_inv = (z1_var_i + 1e-6) ** -0.5 # 1/sqrt(var + epsilon) = 1/std, shape (1, n_hidden)\n",
    "z1_standardized = diff * z1_std_i_inv # (x - mean) / std, shape (m, n_hidden)\n",
    "z1_rescaled = gamma * z1_standardized + beta # gamma * (x - mean) / std + beta, shape (m, n_hidden)\n",
    "# Non-linearity\n",
    "a1 = torch.tanh(z1_rescaled) # shape (m, n_hidden)\n",
    "# Linear layer 2\n",
    "z2 = a1 @ W2 + B2 # shape (m, vocab_size)\n",
    "# Cross-entropy loss\n",
    "logits_maxes = z2.max(dim=1, keepdim=True).values  # shape (m, 1), we used .values to get rid of the indices\n",
    "norm_logits = z2 - logits_maxes # subtract the maximum value for each example for numerical stability, shape (m, vocab_size)\n",
    "counts = norm_logits.exp() # shape (m, vocab_size)\n",
    "counts_sum = counts.sum(dim=1, keepdim=True) # shape (m, 1)\n",
    "counts_sum_inv = counts_sum ** -1 # shape (m, 1)\n",
    "probs = counts * counts_sum_inv # probs = exp(logits) / sum(exp(logits)), shape (m, vocab_size)\n",
    "logprobs = probs.log()  # shape (m, vocab_size)\n",
    "loss = -logprobs[range(m), y_batch].mean() # negative log-likelihood, shape (1,)\n",
    "\n",
    "# Backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "# retain the grad for all the tensors (so that we can compare the gradients)\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, \n",
    "          norm_logits, logits_maxes, z2, a1, z1_rescaled, z1_standardized,\n",
    "           z1_std_i_inv, z1_var_i, diff_sq, diff, z1, z1_mean_i, embcat, emb]:\n",
    "    t.retain_grad()\n",
    "# backprop the loss and compute the gradients using PyTorch's autograd\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the forward pass is significantly expanded than we are used to\n",
    "    - we implemented cross entropy loss ourselves\n",
    "    - we also broke up the implementation to a mangeable pieces, because we will go backwards and calculate the gradients for these chunks (from the bottom to the top)\n",
    "    - in the calculation of variance, we divided by (m-1) instead of m, because the number of examples is small (sample variance not population variance), that is because we are dealing with mini-batches, which is a small sample from the population (the whole dataset)\n",
    "        - or we could use torch.var, with the argument unbiased=True, which will divide by (m-1) instead of m\n",
    "        - by the way, the paper divides by m in training and m-1 in inference, which is wrong and produces a train-test mismatch (or a bug if you may), and pytorch implementation of `BatchNorm1d` followed the paper exactly, that bug would be more of an issue if the batch size is small\n",
    "- we will have d_var, for each variable above, which is the gradient of the loss w.r.t this tensor or variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## backprop through the the whole thing manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs       : Exact: True , Approx: True , Max diff: 0.0\n",
      "probs          : Exact: True , Approx: True , Max diff: 0.0\n",
      "counts_sum_inv : Exact: True , Approx: True , Max diff: 0.0\n",
      "counts_sum     : Exact: True , Approx: True , Max diff: 0.0\n",
      "counts         : Exact: True , Approx: True , Max diff: 0.0\n",
      "norm_logits    : Exact: True , Approx: True , Max diff: 0.0\n",
      "logits_maxes   : Exact: True , Approx: True , Max diff: 0.0\n",
      "z2             : Exact: True , Approx: True , Max diff: 0.0\n",
      "a1             : Exact: True , Approx: True , Max diff: 0.0\n",
      "W2             : Exact: True , Approx: True , Max diff: 0.0\n",
      "B2             : Exact: True , Approx: True , Max diff: 0.0\n",
      "z1_rescaled    : Exact: True , Approx: True , Max diff: 0.0\n",
      "gamma          : Exact: True , Approx: True , Max diff: 0.0\n",
      "beta           : Exact: True , Approx: True , Max diff: 0.0\n",
      "z1_standardized: Exact: True , Approx: True , Max diff: 0.0\n",
      "z1_std_i_inv   : Exact: True , Approx: True , Max diff: 0.0\n",
      "z1_var_i       : Exact: True , Approx: True , Max diff: 0.0\n",
      "diff_sq        : Exact: True , Approx: True , Max diff: 0.0\n",
      "diff           : Exact: True , Approx: True , Max diff: 0.0\n",
      "z1_mean_i      : Exact: True , Approx: True , Max diff: 0.0\n",
      "z1             : Exact: True , Approx: True , Max diff: 0.0\n",
      "embcat         : Exact: True , Approx: True , Max diff: 0.0\n",
      "emb            : Exact: True , Approx: True , Max diff: 0.0\n",
      "W1             : Exact: True , Approx: True , Max diff: 0.0\n",
      "B1             : Exact: True , Approx: True , Max diff: 0.0\n",
      "C              : Exact: True , Approx: True , Max diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# manual backward pass\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(m), y_batch] = -1.0/m\n",
    "dprobs = (1.0 / probs) * dlogprobs # local gradient * upstream,\n",
    "dcounts_sum_inv = (counts * dprobs).sum(dim=1,keepdim=True)\n",
    "dcounts_sum = -1.0/(counts_sum**2) * dcounts_sum_inv\n",
    "# dcoutns from formula 1\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "# dcounts from formula 2\n",
    "dcounts_second_term = torch.ones_like(counts) * dcounts_sum\n",
    "dcounts += dcounts_second_term\n",
    "dnorm_logits = counts * dcounts\n",
    "dlogits_maxes = -1.0 * dnorm_logits.sum(dim=1,keepdim=True)\n",
    "# dz2 first term\n",
    "dz2 = dnorm_logits.clone()\n",
    "# dz2 second term\n",
    "# method1\n",
    "#dz2_second_term = torch.zeros_like(z2).double()\n",
    "#dz2_second_term[range(m),z2.max(dim=1, keepdim=True).indices] = 1\n",
    "# method 2\n",
    "dz2_second_term = F.one_hot(z2.max(dim=1).indices,num_classes=z2.shape[1]).double()\n",
    "dz2_second_term *= dlogits_maxes\n",
    "# add the secoond term derivative\n",
    "dz2 += dz2_second_term\n",
    "\n",
    "da1 = dz2 @ W2.T\n",
    "dW2 = a1.T @ dz2\n",
    "dB2 = dz2.sum(dim=0)\n",
    "\n",
    "dz1_rescaled = (1.0 - a1**2) * da1\n",
    "\n",
    "dgamma = (dz1_rescaled * z1_standardized).sum(dim=0, keepdim=True)\n",
    "dbeta = dz1_rescaled.sum(dim=0, keepdim=True)\n",
    "dz1_standardized = dz1_rescaled * gamma\n",
    "\n",
    "dz1_std_i_inv = (dz1_standardized * diff).sum(dim=0,keepdim=True)\n",
    "\n",
    "dz1_var_i = (-0.5*(z1_var_i+1e-6)**-1.5) * dz1_std_i_inv \n",
    "\n",
    "ddiff_sq = torch.ones_like(diff_sq) * 1.0/(m-1) * dz1_var_i\n",
    "\n",
    "# diff first branch derivative \n",
    "ddiff = 2.0 * diff * ddiff_sq\n",
    "# second branch \n",
    "ddiff +=  z1_std_i_inv * dz1_standardized \n",
    "\n",
    "\n",
    "dz1_mean_i = -1.0 * ddiff.sum(dim=0,keepdim=True)\n",
    "\n",
    "# dz1 first branch diff = z1 - z1_mean_i \n",
    "dz1 = 1.0 * ddiff\n",
    "# second branch z1_mean_i = 1/m * z1.sum(dim=0)\n",
    "dz1_second = torch.ones_like(z1) * (1/m) * dz1_mean_i\n",
    "dz1 += dz1_second\n",
    "\n",
    "dembcat = dz1 @ W1.T\n",
    "dW1 = embcat.T @ dz1\n",
    "dB1 = dz1.sum(dim=0,keepdim=True)\n",
    "demb = dembcat.view(emb.shape)\n",
    "\n",
    "dC = torch.zeros_like(C)\n",
    "# flatten the demb and xbatch reshaped\n",
    "for idx, row in zip(x_batch.view(-1),demb.view(-1,demb.shape[-1])):\n",
    "    dC[idx] += row\n",
    "    \n",
    "    \n",
    "\n",
    "# compare \n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logits_maxes', dlogits_maxes, logits_maxes)\n",
    "cmp('z2', dz2, z2)\n",
    "cmp('a1', da1, a1)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('B2', dB2, B2)\n",
    "cmp('z1_rescaled', dz1_rescaled, z1_rescaled)\n",
    "cmp('gamma', dgamma, gamma)\n",
    "cmp('beta', dbeta, beta)\n",
    "cmp('z1_standardized', dz1_standardized, z1_standardized)\n",
    "cmp('z1_std_i_inv', dz1_std_i_inv, z1_std_i_inv)\n",
    "cmp('z1_var_i', dz1_var_i, z1_var_i)\n",
    "cmp('diff_sq', ddiff_sq, diff_sq)\n",
    "cmp('diff', ddiff, diff)\n",
    "cmp('z1_mean_i', dz1_mean_i, z1_mean_i)\n",
    "cmp('z1', dz1, z1)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('B1', dB1, B1)\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- before we start, we need to state that dvar is the same shape as var\n",
    "    - that is because we want to calculate the gradient of the loss w.r.t all the elements in the tensor for all the tensors in the neural network, and whatever elements contributed to the loss, they will have a value, and if other elements didn't contribute to the loss, they will have a 0 gradient \n",
    "- dlogpropbs\n",
    "    - in the forward prop, shape (m, vocab_size), we took some elements (for each row, we took the index of the actual next token), then we multiplied these numbers by -1, then we took their mean\n",
    "        - so if y = -x1 - x2 - x3, then dy/dx1 = -1/3, dy/dx2 = -1/3, dy/dx3 = -1/3\n",
    "            - so in case of taking the mean of m elements (examples), the gradient of the mean (loss) w.r.t each element is 1/m (-1/m because we multiplied by -1)\n",
    "        - since dlogpropbs is the same shape as logpropbs, we initialize it with 0s and then index to the elements that contributed to the loss and assign them -1/m\n",
    "\n",
    "-  dprops\n",
    "    - in the forward pass we took each element in probs and applied the log function, so if $y = log(x)$, then $\\frac{dy}{dx} = \\frac{1}{x}$\n",
    "    - in out case we have $logprops = log(probs)$, so $\\frac{dlogprops}{dprobs} = \\frac{1}{probs}$, that is the local gradient of the log function\n",
    "    - from the chain rule, $\\frac{dloss}{dprobs} = \\frac{dloss}{dlogprops} \\times \\frac{dlogprops}{dprobs}$ which is $dlogprops \\times \\frac{1}{probs}$\n",
    "    - what this intuitively does is that if probs is high (say 1), then the local gradient is 1, then upstream gradient will pass as it is, but if probs is low (say 0.1), then the local gradient is 10, then the upstream gradient will be boosted by 10\n",
    "\n",
    "- dcounts_sum_inv\n",
    "    - notice that counts_sum_inv is of shape (m, 1), so dcounts_sum_inv will be of the same shape\n",
    "    - $\\text{props} = \\text{counts} * \\text{counts\\_sum\\_inv}$, so $\\frac{dprops}{dcounts\\_sum\\_inv} = \\text{counts}$, which is of shape (m, vocab_size)\n",
    "    - using the chain rule, $\\frac{dloss}{dcounts\\_sum\\_inv} = \\frac{dloss}{dprops} \\times \\frac{dprops}{dcounts\\_sum\\_inv}$, which is $dprops \\times counts$ and that is of shape (m, vocab_size)\n",
    "    - we will sum over the vocab_size axis (dim = 1) to get the gradient of the loss w.r.t counts_sum_inv (which is of shape (m, 1))\n",
    "        - mine: think of it that way, whenever we broadcast a tensor to a bigger tensor, it is like using this tensor multiple times, so the gradient will be summed for all of the copies, so we calculate the gradient w.r.t the broadcasted tensor, then sum over the axis that was broadcasted\n",
    "\n",
    "- dcounts_sum\n",
    "    - since $counts\\_sum\\_inv = \\frac{1}{counts\\_sum}$, and we know that if $y = \\frac{1}{x}$, then $\\frac{dy}{dx} = -\\frac{1}{x^2}$. then $\\frac{dcounts\\_sum\\_inv}{dcounts\\_sum} = -\\frac{1}{counts\\_sum^2}$ (that is the local gradient)\n",
    "    - from the chain rule, $\\frac{dloss}{dcounts\\_sum} = \\frac{dloss}{dcounts\\_sum\\_inv} \\times \\frac{dcounts\\_sum\\_inv}{dcounts\\_sum}$, which is $dcounts\\_sum\\_inv \\times -\\frac{1}{counts\\_sum^2}$   \n",
    "\n",
    "- dcounts\n",
    "    - counts is used in 2 formulas, so it will receive gradients from 2 sources\n",
    "        - $\\text{props} = \\text{counts} * \\text{counts\\_sum\\_inv}$ \n",
    "        - $\\text{counts\\_sum} = \\text{counts.sum(dim=1, keepdim=True)}$\n",
    "    - forumla 1\n",
    "        - since $\\text{props} = \\text{counts} * \\text{counts\\_sum\\_inv}$, then $\\frac{dprops}{dcounts} = \\text{counts\\_sum\\_inv}$, which is of shape (m, 1), so we will broadcast it -to get the same tensor that was broadcasted implicitly in the forward pass- then multiply it by dprops (shape (m, vocab_size)) to get dcounts\n",
    "        - we won't actually broadcast it explicitly, when we multiply it by dprops, it will be broadcasted implicitly just like in the forward pass\n",
    "    - formula 2\n",
    "        - $\\text{counts\\_sum} = \\text{counts.sum(dim=1, keepdim=True)}$, so basically we are summing over the vocab_size axis, if $y = x1 + x2 + x3$, then $\\frac{dy}{dx1} = 1$, $\\frac{dy}{dx2} = 1$, $\\frac{dy}{dx3} = 1$, so the local gradient is 1, then the upstream gradient will pass as it is\n",
    "        - in other words, we know that when we sum multiple elements, the upstream gradient will be routed to all the elements that were summed, this is exactly what we will do, and the upstream gradient for each row in counts is the corresponding row in dcounts_sum\n",
    "        - example $counts = \\begin{bmatrix} a1 & a2 & a3 \\\\ b1 & b2 & b3 \\end{bmatrix}$, $counts\\_sum = \\begin{bmatrix} a1 + a2 + a3 \\\\ b1 + b2 + b3 \\end{bmatrix}$, $dcounts\\_sum = \\begin{bmatrix} da \\\\ db \\end{bmatrix}$, then $dcounts = \\begin{bmatrix} da & da & da \\\\ db & db & db \\end{bmatrix}$\n",
    "\n",
    "- dnorm_logits\n",
    "    - in the forward pass, we have $counts = e^{norm_logits}$, since if $y = e^x$, then $\\frac{dy}{dx} = e^x$ which is y itself, then $\\frac{dcounts}{dnorm\\_logits} = e^{norm\\_logits} = counts$ \n",
    "    - from the chain rule, $\\frac{dloss}{dnorm\\_logits} = \\frac{dloss}{dcounts} \\times \\frac{dcounts}{dnorm\\_logits}$, which is $dcounts \\times counts$\n",
    "\n",
    "- dlogit_maxes\n",
    "    - since in the forward prop $norm\\_logits_{m , vocab\\_size} = logits_{m , vocab\\_size} - logit\\_maxes_{m, 1}$, \n",
    "    - since logit_maxes was broadcasted, then -as usual- we will calculate the gradient of the loss then sum over the axis that was broadcasted\n",
    "    - if $y = x - c$, then $\\frac{dy}{cx} = -1$, then $\\frac{norm\\_logits}{dlogit\\_maxes} = -1$  \n",
    "    - from the chain rule, $\\frac{dloss}{dlogit\\_maxes} = \\frac{dloss}{dnorm\\_logits} \\times \\frac{dnorm\\_logits}{dlogit\\_maxes}$, which is $dnorm\\_logits \\times -1$, and the result will be of shape (m, vocab_size)\n",
    "        - so we will sum over the vocab_size axis (dim = 1) to get the gradient of the loss w.r.t logit_maxes (which is of shape (m, 1))\n",
    "    - `intuition`: we said that the only purpose of subtracting the max from the logits is to avoid numerical instability when we exponentiate the logits then calculate the probabilities\n",
    "        - so, no matter what value of logit_maxes are, they are not changing the probabilities -since the probabilities with or without them is the same-, and therefore, they are not changing the loss\n",
    "        - so, we expect that the gradient of the loss w.r.t logit_maxes to be 0s, and indeed that is what we get -check the code cell below- (we actually get very small numbers on the order of 1e-9) because floating point wonkiness and approximation errors\n",
    "        - therefore, in the following code \n",
    "        ```python\n",
    "        z2 = W2 @ a1 + b2\n",
    "        logit_maxes = z2.max(dim=1, keepdim=True).values\n",
    "        norm_logits = z2 - logit_maxes\n",
    "        ```\n",
    "        the logit maxes subtraction is not doing anything new and therefore dz2 (dlogits) should be the same as dnorm_logits, and this is also indeed what we get -check the code cell below-\n",
    "- dz2\n",
    "    - z2 is of shape (m, vocab_size), so dz2 will be of the same shape\n",
    "    - z2 is used in 2 formulas, so it will receive gradients from 2 sources\n",
    "        - $norm\\_logits = z2 - logit\\_maxes$\n",
    "        - $logit\\_maxes = z2.max(dim=1, keepdim=True)$\n",
    "\n",
    "    - formula 1\n",
    "        - $norm\\_logits = z2 - logit\\_maxes$, so $\\frac{dnorm\\_logits}{dz2} = 1$, so from the chain rule, $\\frac{dloss}{dz2} = \\frac{dloss}{dnorm\\_logits} \\times \\frac{dnorm\\_logits}{dz2}$, which is $dnorm\\_logits \\times 1$\n",
    "    - formula 2\n",
    "        - $logit\\_maxes = z2.max(dim=1, keepdim=True)$, so basically for each row in logit_maxes, we are taking the max of the row in z2, so the backpropagation will be routed to these elements for each row in z2\n",
    "        - the local gradient is 1, so the upstream gradient will pass as it is\n",
    "        - so we will start with a tensor of the same shape as z2, it will be all 0s, then we will index to the max elements in each row and set the local gradient to 1\n",
    "        - then we will multiply this tensor by dlogit_maxes (the 1 in each row will be multiplied by the corresponding element in dlogit_maxes)\n",
    "        - we can do it another way, by taking the one hot of the max indices -will be the sme as having an array of 0s then index to the max elements and set them to 1s- then multiply it by dlogit_maxes\n",
    "- da1, dW2, db2\n",
    "    - a1 is of shape (m, hidden_size), so da1 will be of the same shape\n",
    "    - a1 is used in $z2 = W2 @ a1 + b2$\n",
    "\n",
    "    ![matrix multiplication](assets/matrix_mul_derivatives.png)\n",
    "\n",
    "    we just took a small example and derived it to understand the pattern, we first expressed matrix multiplication in terms of multiplications and additions, then we derived $dL/da1$ and $dL/dW2$ and so on (with additions in between the terms because it was used in multiple paths), then we re-arranged $dL/da$ in a matrix of the same shape as a, and found that the derivative is just a matrix multiplication as well\n",
    "        - so if d = a @ b, then $dL/da = dL/dd \\times b^T$\n",
    "    - using the same reasoning, we can derive the rest\n",
    "        - so if $z = W @ a + b$, then \n",
    "            - $\\frac{dl}{da} = \\frac{dl}{dz} \\times W^T$\n",
    "\n",
    "            - $\\frac{dl}{dW} = a^T \\times \\frac{dl}{dz}$\n",
    "\n",
    "            - $\\frac{dl}{db} = \\frac{dl}{dz}.sum(dim=0)$\n",
    "    - spoiler alert, you can infer the formulas from the shapes analysis as they have to work out\n",
    "\n",
    "- z1_rescaled\n",
    "    - z1_rescaled is of shape (m, hidden_size), so dz1_rescaled will be of the same shape\n",
    "    - $a1 = tanh(z1_rescaled)$, since $y = tanh(x)$, then $\\frac{dy}{dx} = 1 - y^2$, then $\\frac{da_1}{dz_1\\_rescaled} = 1 - a_1^2$\n",
    "    - from the chain rule, $\\frac{dloss}{dz1\\_rescaled} = \\frac{dloss}{da1} \\times \\frac{da1}{dz1\\_rescaled}$, which is $da1 \\times (1 - a1^2)$\n",
    "    \n",
    "\n",
    "- dgamma, dbeta, dz1_rescaled\n",
    "    - since gamma is of shape (1, hidden_size), then dgamma will be of the same shape\n",
    "        - in the forward prop we have $z1_rescaled = gamma * z1 + beta$, since it is simple element-wise multiplication, then $\\frac{dz1\\_rescaled}{dgamma} = z1$, then from the chain rule, $\\frac{dloss}{dgamma} = \\frac{dloss}{dz1\\_rescaled} \\times \\frac{dz1\\_rescaled}{dgamma}$, which is $dz1\\_rescaled \\times z1$\n",
    "        - gamma was broadcasted for all the examples (from shape (1, hidden_size) to (m, hidden_size)), so we will take the above result, which is of shape (m, hidden_size), then sum over the examples axis (dim = 0) -replecated in the forward pass so we accumulate the gradients for all the replications-\n",
    "    - as for beta -shape (1, hidden_size)-, $\\frac{dz1\\_rescaled}{dbeta} = 1$, \n",
    "    - then from the chain rule, $\\frac{dloss}{dbeta} = \\frac{dloss}{dz1\\_rescaled} \\times \\frac{dz1\\_rescaled}{dbeta}$, which is $dz1\\_rescaled \\times 1$\n",
    "        - beta was broadcasted for all the examples (from shape (1, hidden_size) to (m, hidden_size)), so we will take the above result, which is of shape (m, hidden_size), then sum over the examples axis (dim = 0) \n",
    "    - as for dz1_rescaled, since $z1_rescaled = gamma * z1 + beta$, then $\\frac{dz1\\_rescaled}{dz1} = gamma$, then from the chain rule, $\\frac{dloss}{dz1} = \\frac{dloss}{dz1\\_rescaled} \\times \\frac{dz1\\_rescaled}{dz1}$, which is $dz1\\_rescaled \\times gamma$, gamma is of shape (1, hidden_size), but when we multiply it by dz1_rescaled, it will be broadcasted implicitly just like in the forward pass\n",
    "\n",
    "- z1_std_i_inv\n",
    "    - z1_std_i_inv is of shape (m, hidden_size), so dz1_std_i_inv will be of the same shape\n",
    "    - $z1_standardized = diff * z1\\_std\\_i\\_inv$, then from the chain rule, $\\frac{dloss}{dz1\\_std\\_i\\_inv} = \\frac{dloss}{dz1\\_standardized} \\times \\frac{dz1\\_standardized}{dz1\\_std\\_i\\_inv}$, which is $dz1\\_standardized \\times diff$ notice that the result is of shape (m, hidden_size), because $z1\\_std\\_i\\_inv$ was broadcasted for all the examples, so we will sum over the examples axis (dim = 0) \n",
    "        - `as you can see whenever an element is broadcasted, its derivative is summed over the axis that was broadcasted`\n",
    "\n",
    "- z1_var_i\n",
    "    - z1_var_i is of shape (m, hidden_size), so dz1_var_i will be of the same shape\n",
    "    - $z1\\_std\\_i\\_inv = (z1\\_var\\_i + eps)^-0.5$, if $y = x^-0.5$, then $\\frac{dy}{dx} = -0.5x^-1.5$, then $\\frac{dz1\\_std\\_i\\_inv}{dz1\\_var\\_i} = -0.5(z1\\_var\\_i + eps)^{-1.5}$\n",
    "    - from the chain rule, $\\frac{dloss}{dz1\\_var\\_i} = \\frac{dloss}{dz1\\_std\\_i\\_inv} \\times \\frac{dz1\\_std\\_i\\_inv}{dz1\\_var\\_i}$, which is $dz1\\_std\\_i\\_inv \\times -0.5(z1\\_var\\_i + eps)^{-1.5}$\n",
    "\n",
    "- ddiff_sq\n",
    "    - diff_sq is of shape (m, hidden_size), so ddiff_sq will be of the same shape\n",
    "    - in the forward pass, we have $z1\\_var\\_i = \\frac{1}{m} \\times diff\\_sq.sum(dim=0)$, \n",
    "    - so the the rows were accumulated for each column and produced a row vector $z1\\_var\\_i$, so each upstream gradient in $dz1\\_var\\_i$ will be routed to the corresponding column in $diff\\_sq$\n",
    "        - so we will start with a tensor of the same shape as diff_sq, it will be all 1s, but we will multiply with (1/m) since we multiplied with it in the forward prop, then we will multiply that matrix by dz1_var_i (each element in $dz1\\_var\\_i$ will be broadcasted -routed- to the corresponding column in $diff\\_sq$)\n",
    "    - example $diff\\_sq = \\begin{bmatrix} a1 & a2 & a3 \\\\ b1 & b2 & b3 \\end{bmatrix}$, $dz1\\_var\\_i = \\begin{bmatrix} da & db & dc \\end{bmatrix}$, then $ddiff\\_sq = \\begin{bmatrix} da/(m-1) & db/(m-1) & dc/(m-1) \\\\ da/(m-1) & db/(m-1) & dc/(m-1) \\end{bmatrix}$\n",
    "\n",
    "- diff \n",
    "    - diff is of shape (m, hidden_size), so ddiff will be of the same shape\n",
    "    - it is used in 2 formulas\n",
    "        - $diff_sq = diff^2$\n",
    "        - $z1\\_standardized = diff * z1\\_std\\_i\\_inv$\n",
    "    - formula 1\n",
    "        - $diff_sq = diff^2$, so $\\frac{ddiff\\_sq}{ddiff} = 2 \\times diff$, which is of shape (m, hidden_size)\n",
    "        - from the chain rule, $\\frac{dloss}{ddiff} = \\frac{dloss}{ddiff\\_sq} \\times \\frac{ddiff\\_sq}{ddiff}$, which is $ddiff\\_sq \\times 2 \\times diff$\n",
    "    - formula 2\n",
    "        - $z1_standardized = diff * z1\\_std\\_i\\_inv$, so $\\frac{dz1\\_standardized}{ddiff} = z1\\_std\\_i\\_inv$, which is of shape (1, hidden_size), but when we multiply it by dz1_standardized, it will be broadcasted implicitly just like in the forward pass\n",
    "        - from the chain rule, $\\frac{dloss}{ddiff} = \\frac{dloss}{dz1\\_standardized} \\times \\frac{dz1\\_standardized}{ddiff}$, which is $dz1\\_standardized \\times z1\\_std\\_i\\_inv$\n",
    "\n",
    "- dz1_mean_i\n",
    "    - z1_mean_i is of shape (1, hidden_size), so dz1_mean_i will be of the same shape\n",
    "    - in the forward pass $diff = z1 - z1_mean_i$ so $\\frac{ddiff}{dz1\\_mean\\_i} = -1$, then from the chain rule, $\\frac{dloss}{dz1\\_mean\\_i} = \\frac{dloss}{ddiff} \\times \\frac{ddiff}{dz1\\_mean\\_i}$, which is $ddiff \\times -1$\n",
    "        - but since the result is of shape (m, hidden_size), because z1_mean_i was broadcasted for all the examples, so we will sum the derivative coming from all examples (dim=0) so that it will be of shape (1, hidden_size)\n",
    "\n",
    "- dz1\n",
    "    - has a shape of (m, hidden_size), so dz1 will be of the same shape\n",
    "    - it was used in 2 places in the forward pass\n",
    "        - $diff = z1 - z1_mean_i$\n",
    "        - $z1_mean_i = \\frac{1}{m} \\times z1.sum(dim=0)$\n",
    "    - formula 1\n",
    "        - $diff = z1 - z1_mean_i$, so $\\frac{ddiff}{dz1} = 1$, then from the chain rule, $\\frac{dloss}{dz1} = \\frac{dloss}{ddiff} \\times \\frac{ddiff}{dz1}$, which is $ddiff \\times 1$\n",
    "    - formula 2\n",
    "        - since we summed the rows for each column in z1, then dz1 will be routed for each column to z1, so we start with an array of ones of the same shape as z1, then multiply it with (1/m) since we multiplied with that in the forward pass, then we multiply that array with the upsteam gradient z1_mean_i (it will be broadcasted for all the rows, with different value routed for each column)\n",
    "            - in other words, each column summed its rows, so the result will be routed for all the terms in that column\n",
    "- demb_cat, dW1, dB1\n",
    "    - $z1 = emb_cat @ W1 + B1$, which is similar to a1,W2,B2 above, i won't write it down\n",
    "- emb\n",
    "    - since $embcat = emb.view(m,-1)$ basically a reshaping, so the gradient of emb is the same as embcat (dembcat) but reshape it to be of the same shape as emb\n",
    "\n",
    "- dC\n",
    "    - C is the embedding matrix, of shape (vocab_size,embed_dim), we index with the word index in the vocabulary and get the corresponding embedding vector\n",
    "    - since $emb = C[x\\_batch]$ where x_batch is of shape (m,block_size), and contains the indices of the characters (3 characters per row), and the result emb is of shape (m,block_size,embed_dim), which is the embedding vector -instead of the scalar indices of x_batch-\n",
    "    - now in the backprop we have demb of shape (m,block_size,embed_dim), that contains the derivatives of the embeddings, since we just blucked out different rows of C, then these gradients are the gradients of different rows of C\n",
    "    - so we re-arrange demb to be of shape (m*block_size,embed_dim), (basically flattened the block size into individual rows), and we do the same thing to x_batch (from shape (m,block_size) to (m*block_size,1)), then we loop on the rows gradients, use the flattened x_batch to index the corresponding row in C, then accumulate the corresponding gradient in the flattened demb\n",
    "\n",
    "- remember: a broadcast in the forward pass, means a variable reuse, therfore a sum in the backward pass\n",
    "- tip: avoid tensor a = tensor b, because that makes a and b point to the same thing, we can use tensor a = b.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.9849e-10],\n",
       "        [ 9.3132e-10],\n",
       "        [ 9.3132e-10],\n",
       "        [-4.6566e-10],\n",
       "        [-2.5611e-09],\n",
       "        [ 2.7940e-09],\n",
       "        [ 7.4506e-09],\n",
       "        [ 6.9849e-10],\n",
       "        [-1.8626e-09],\n",
       "        [-4.1910e-09],\n",
       "        [-1.8626e-09],\n",
       "        [-2.5611e-09],\n",
       "        [ 2.0955e-09],\n",
       "        [-5.1223e-09],\n",
       "        [ 4.6566e-09],\n",
       "        [ 9.3132e-10],\n",
       "        [-3.7253e-09],\n",
       "        [-0.0000e+00],\n",
       "        [ 5.1223e-09],\n",
       "        [ 1.8626e-09],\n",
       "        [-1.1642e-09],\n",
       "        [ 2.0955e-09],\n",
       "        [-6.0536e-09],\n",
       "        [ 3.9581e-09],\n",
       "        [-5.5879e-09],\n",
       "        [ 2.3283e-09],\n",
       "        [-0.0000e+00],\n",
       "        [ 4.6566e-10],\n",
       "        [-2.7940e-09],\n",
       "        [-4.4238e-09],\n",
       "        [-1.8626e-09],\n",
       "        [ 6.7521e-09]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the maxes won't affect the probabilities calculated therfore won't affect the loss, therefore they are all 0s\n",
    "dlogits_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(dz2,dnorm_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprop through the loss\n",
    "- what we did above is not what we will do in practice, we said that we can use larger blocks in forward prob, as long as we can derive their backward calculation\n",
    "- so, we will backpropagate through the loss function as a single block\n",
    "- we can do the differentiation on the larger block, and a lot of terms cancel and simplify, and the mathematical expression we end up with is significantly shorter and easier to implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.37553071975708 Difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "# before \n",
    "# logits_maxes = z2.max(dim=1, keepdim=True).values  # shape (m, 1), we used .values to get rid of the indices\n",
    "# norm_logits = z2 - logits_maxes # subtract the maximum value for each example for numerical stability, shape (m, vocab_size)\n",
    "# counts = norm_logits.exp() # shape (m, vocab_size)\n",
    "# counts_sum = counts.sum(dim=1, keepdim=True) # shape (m, 1)\n",
    "# counts_sum_inv = counts_sum ** -1 # shape (m, 1)\n",
    "# probs = counts * counts_sum_inv # probs = exp(logits) / sum(exp(logits)), shape (m, vocab_size)\n",
    "# logprobs = probs.log()  # shape (m, vocab_size)\n",
    "# loss = -logprobs[range(m), y_batch].mean() # negative log-likelihood, shape (1,)\n",
    "\n",
    "loss_fast = F.cross_entropy(z2,y_batch)\n",
    "print(loss_fast.item(), f\"Difference: {loss_fast-loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![backprop through the loss](assets/cross_entropy_loss_derivative.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- so the derivative is basically the probabilities themselves, then we index to the actual next token in the probabilities and subtract 1 from it\n",
    "\n",
    "- but the loss above is for a single example, for multiple examples, it is also the same but we take the mean of the losses (we divide by m in the forward prob), so we will also divide by m in the backward prob (mine:because we backpropagate that mean of the losses not each loss to each example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z2             : Exact: False, Approx: True , Max diff: 7.2177499532699585e-09\n"
     ]
    }
   ],
   "source": [
    "dz2_fast = probs.clone()\n",
    "dz2_fast[range(m),y_batch] -= 1\n",
    "dz2_fast /= m\n",
    "cmp(\"Z2\", dz2_fast,z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we did not get the exact same result because of floating point wonkness, but the results are very close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- logits gradients intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25afe8bea50>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(dz2.detach(),cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we know that the logits determine the probabilities, we see above the gradients of the logits, they are the probabilities themselves except for the -1 for the actual next token logit, what does that mean?\n",
    "    - in the ideal case logits would be all 0s except for the actual next token logit which would be 1\n",
    "        - then the gradients will be the probs themselves for the rest of the tokens (which are 0s), and probs-1 for the actual next token (which is 1-1 = 0), so in the ideal case, the gradients are all 0s, and this makes sense because we don't want to change anything in the logits in the ideal case\n",
    "    - until we reach that ideal case\n",
    "        - the wrong tokens logits will have probabilities > 0, and these probabilities are the gradients themselves (mine: +ve because we want to decrease them, assuming we can change z directly, z = z - lr * dz, but actually we don't decrease z directly but rather the weights and biases that produce z, that is why we further backpropagate it, but this is just so that we understand the intuition behind the sign of the gradients)\n",
    "            - and the more the wrong logits are, the higher their probability -gradient- will be, so the more we will decrease them\n",
    "        - the right token logit will have probability < 1, and the gradient will be this probability - 1, so it will be the difference in negative, (mine: because we want to increase it)\n",
    "            - and the lower the right logit is, the lower its probability, and the higher its negative different from 1, so the more we will increase it\n",
    "\n",
    "- so think of these gradients as a force that pushes the logits of the wrong tokens down and the right token up (with amounts that are proportional to the probabilities that came out of these logits), and the amount of push and pull is exactly equal (if we summed the logits gradients -that is the +ve terms for the wrong tokens and the -ve term for the right token- we will get 0) as we see below\n",
    "    - think of the neural network now as a massive pully system or something like that, we change the weights and biases to change the logits, to pull the logits of the wrong tokens down and the right token up, and we do that for all examples\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-6.9849e-10, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dz2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprop through BatchNorm\n",
    "- we will backpropagate through the batchnorm as a single block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max diff: tensor(4.2915e-06, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# before\n",
    "# z1 = embcat @ W1 + B1 # shape (m, n_hidden)\n",
    "# # Batch norm\n",
    "# z1_mean_i = 1/m * z1.sum(dim=0, keepdim=True) # mean = sum(x) / n, shape (1, n_hidden)\n",
    "# diff = z1 - z1_mean_i # x - mean, shape (m, n_hidden)\n",
    "# diff_sq = diff ** 2 # (x - mean) ** 2, shape (m, n_hidden)\n",
    "# z1_var_i = 1/(m-1) * diff_sq.sum(dim=0,keepdim=True) # var = sum((x - mean) ** 2) / (n-1), we used n-1 which is bassel's correction, shape (1, n_hidden)\n",
    "# z1_std_i_inv = (z1_var_i + 1e-6) ** -0.5 # 1/sqrt(var + epsilon) = 1/std, shape (1, n_hidden)\n",
    "# z1_standardized = diff * z1_std_i_inv # (x - mean) / std, shape (m, n_hidden)\n",
    "# z1_rescaled = gamma * z1_standardized + beta # gamma * (x - mean) / std + beta, shape (m, n_hidden)\n",
    "\n",
    "z1_rescaled_fast = gamma * ((z1 - z1.mean(dim=0,keepdim=True)) / torch.sqrt(z1.var(dim=0,keepdim=True,unbiased=True))) + beta\n",
    "print(\"Max diff:\", (z1_rescaled_fast-z1_rescaled).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z1             : Exact: False, Approx: True , Max diff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "# calcualat the gradient of the loss with respect to z1\n",
    "dz1 = gamma*z1_std_i_inv/m * (m*dz1_rescaled - dz1_rescaled.sum(dim=0) - m/(m-1) * z1_standardized * (dz1_rescaled * z1_standardized).sum(dim=0))\n",
    "cmp(\"Z1\",dz1,z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "- we will replace loss.backwards() with our own backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182437, 3]) torch.Size([182437])\n",
      "torch.Size([22781, 3]) torch.Size([22781])\n",
      "torch.Size([22928, 3]) torch.Size([22928])\n"
     ]
    }
   ],
   "source": [
    "block_size = 3\n",
    "def build_dataset(words):\n",
    "    #block_size = 4 # context length: how many characters do we take to predict the next one\n",
    "    Y, X = [], []\n",
    "    for word in words:\n",
    "        #print(word)\n",
    "        context = ['.'] * block_size  + list(word) + ['.']\n",
    "        for i in range(len(word) + 1):\n",
    "            X.append([stoi[ch] for ch in context[i:i+block_size]]) # append at index i, i+1, i+2 (i+3 is the label, that is why it is excluded here)\n",
    "            Y.append(stoi[context[i+block_size]]) # append the character i+3 as the label\n",
    "            #print(''.join(context[i:i+block_size]), '->', context[i+block_size])\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "# shuffle the words\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "\n",
    "x_train, y_train = build_dataset(words[:n1])\n",
    "x_val, y_val = build_dataset(words[n1:n2])\n",
    "x_test, y_test = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embed = 10\n",
    "n_hidden = 64\n",
    "vocab_size = len(stoi)\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((vocab_size, n_embed),             generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embed * block_size, n_hidden), generator=g) * (5/3)/((n_embed * block_size) ** 0.5)\n",
    "B1 = torch.randn((1,n_hidden),                         generator=g) * 0.1 # just for fun, it is useless because of batch norm\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),           generator=g) * 0.1 # make the neural network unconfident\n",
    "B2 = torch.randn(vocab_size,                       generator=g) * 0.1 \n",
    "# Batch norm parameters\n",
    "gamma = torch.randn((1, n_hidden),                 generator=g)\n",
    "beta = torch.randn((1, n_hidden),                  generator=g)\n",
    "\n",
    "\n",
    "parameters = [C, W1, B1, W2, B2, gamma, beta]\n",
    "print(sum(p.numel() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0.00% 2.130618095397949\n"
     ]
    }
   ],
   "source": [
    "steps = 10000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "m = batch_size\n",
    "\n",
    "for i in range(steps):\n",
    "    idx = torch.randint(0, len(x_train), (batch_size,))\n",
    "    x_batch = x_train[idx]\n",
    "    y_batch = y_train[idx]\n",
    "    emb = C[x_batch] # shape (m, block_size, n_embed)\n",
    "    embcat = emb.view(m, -1) # shape (m, block_size * n_embed)\n",
    "    # Linear layer 1\n",
    "    z1 = embcat @ W1 + B1 # shape (m, n_hidden)\n",
    "    # Batch norm\n",
    "    z1_mean_i = 1/m * z1.sum(dim=0, keepdim=True) # mean = sum(x) / n, shape (1, n_hidden)\n",
    "    diff = z1 - z1_mean_i # x - mean, shape (m, n_hidden)\n",
    "    diff_sq = diff ** 2 # (x - mean) ** 2, shape (m, n_hidden)\n",
    "    z1_var_i = 1/(m-1) * diff_sq.sum(dim=0,keepdim=True) # var = sum((x - mean) ** 2) / (n-1), we used n-1 which is bassel's correction, shape (1, n_hidden)\n",
    "    z1_std_i_inv = (z1_var_i + 1e-6) ** -0.5 # 1/sqrt(var + epsilon) = 1/std, shape (1, n_hidden)\n",
    "    z1_standardized = diff * z1_std_i_inv # (x - mean) / std, shape (m, n_hidden)\n",
    "    z1_rescaled = gamma * z1_standardized + beta # gamma * (x - mean) / std + beta, shape (m, n_hidden)\n",
    "    #z1_rescaled = gamma * ((z1 - z1.mean(dim=0,keepdim=True)) / torch.sqrt(z1.var(dim=0,keepdim=True,unbiased=True))) + beta\n",
    "    \n",
    "   \n",
    "    # Non-linearity\n",
    "    a1 = torch.tanh(z1_rescaled) # shape (m, n_hidden)\n",
    "    # Linear layer 2\n",
    "    z2 = a1 @ W2 + B2 # shape (m, vocab_size)\n",
    "    \n",
    "    # Cross-entropy loss\n",
    "    # logits_maxes = z2.max(dim=1, keepdim=True).values  # shape (m, 1), we used .values to get rid of the indices\n",
    "    # norm_logits = z2 - logits_maxes # subtract the maximum value for each example for numerical stability, shape (m, vocab_size)\n",
    "    # counts = norm_logits.exp() # shape (m, vocab_size)\n",
    "    # counts_sum = counts.sum(dim=1, keepdim=True) # shape (m, 1)\n",
    "    # counts_sum_inv = counts_sum ** -1 # shape (m, 1)\n",
    "    # probs = counts * counts_sum_inv # probs = exp(logits) / sum(exp(logits)), shape (m, vocab_size)\n",
    "    # logprobs = probs.log()  # shape (m, vocab_size)\n",
    "    # loss = -logprobs[range(m), y_batch].mean() # negative log-likelihood, shape (1,)\n",
    "    loss = F.cross_entropy(z2,y_batch)\n",
    "\n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    # retain the grad for all the tensors (so that we can compare the gradients)\n",
    "    # for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, \n",
    "    #         norm_logits, logits_maxes, z2, a1, z1_rescaled, z1_standardized,\n",
    "    #         z1_std_i_inv, z1_var_i, diff_sq, diff, z1, z1_mean_i, embcat, emb]:\n",
    "    #     t.retain_grad()\n",
    "    # backprop the loss and compute the gradients using PyTorch's autograd\n",
    "    loss.backward()\n",
    "\n",
    "    # manual backward pass\n",
    "    # dlogprobs = torch.zeros_like(logprobs)\n",
    "    # dlogprobs[range(m), y_batch] = -1.0/m\n",
    "    # dprobs = (1.0 / probs) * dlogprobs # local gradient * upstream,\n",
    "    # dcounts_sum_inv = (counts * dprobs).sum(dim=1,keepdim=True)\n",
    "    # dcounts_sum = -1.0/(counts_sum**2) * dcounts_sum_inv\n",
    "    # # dcoutns from formula 1\n",
    "    # dcounts = counts_sum_inv * dprobs\n",
    "    # # dcounts from formula 2\n",
    "    # dcounts_second_term = torch.ones_like(counts) * dcounts_sum\n",
    "    # dcounts += dcounts_second_term\n",
    "    # dnorm_logits = counts * dcounts\n",
    "    # dlogits_maxes = -1.0 * dnorm_logits.sum(dim=1,keepdim=True)\n",
    "    # # dz2 first term\n",
    "    # dz2 = dnorm_logits.clone()\n",
    "    # # dz2 second term\n",
    "    # # method1\n",
    "    # #dz2_second_term = torch.zeros_like(z2).double()\n",
    "    # #dz2_second_term[range(m),z2.max(dim=1, keepdim=True).indices] = 1\n",
    "    # # method 2\n",
    "    # dz2_second_term = F.one_hot(z2.max(dim=1).indices,num_classes=z2.shape[1]).double()\n",
    "    # dz2_second_term *= dlogits_maxes\n",
    "    # # add the secoond term derivative\n",
    "    # dz2 += dz2_second_term\n",
    "    dz2 = F.softmax(z2,dim=1)\n",
    "    dz2[range(m),y_batch] -= 1\n",
    "    dz2 /= m\n",
    "\n",
    "    da1 = dz2 @ W2.T\n",
    "    dW2 = a1.T @ dz2\n",
    "    dB2 = dz2.sum(dim=0)\n",
    "\n",
    "    dz1_rescaled = (1.0 - a1**2) * da1\n",
    "\n",
    "    dgamma = (dz1_rescaled * z1_standardized).sum(dim=0, keepdim=True)\n",
    "    dbeta = dz1_rescaled.sum(dim=0, keepdim=True)\n",
    "    dz1_standardized = dz1_rescaled * gamma\n",
    "\n",
    "    dz1_std_i_inv = (dz1_standardized * diff).sum(dim=0,keepdim=True)\n",
    "\n",
    "    dz1_var_i = (-0.5*(z1_var_i+1e-6)**-1.5) * dz1_std_i_inv \n",
    "\n",
    "    ddiff_sq = torch.ones_like(diff_sq) * 1.0/(m-1) * dz1_var_i\n",
    "\n",
    "    # diff first branch derivative \n",
    "    ddiff = 2.0 * diff * ddiff_sq\n",
    "    # second branch \n",
    "    ddiff +=  z1_std_i_inv * dz1_standardized \n",
    "\n",
    "\n",
    "    dz1_mean_i = -1.0 * ddiff.sum(dim=0,keepdim=True)\n",
    "\n",
    "    # dz1 first branch diff = z1 - z1_mean_i \n",
    "    dz1 = 1.0 * ddiff\n",
    "    # second branch z1_mean_i = 1/m * z1.sum(dim=0)\n",
    "    dz1_second = torch.ones_like(z1) * (1/m) * dz1_mean_i\n",
    "    dz1 += dz1_second\n",
    "    #dz1 = gamma * z1_std_i_inv /m * (m*dz1_rescaled - dz1_rescaled.sum(dim=0,keepdim=True) - m/(m-1) * z1_standardized * (dz1_rescaled * z1_standardized).sum(dim=0,keepdim=True))\n",
    "\n",
    "    dembcat = dz1 @ W1.T\n",
    "    dW1 = embcat.T @ dz1\n",
    "    dB1 = dz1.sum(dim=0,keepdim=True)\n",
    "    demb = dembcat.view(emb.shape)\n",
    "\n",
    "    dC = torch.zeros_like(C)\n",
    "    # flatten the demb and xbatch reshaped\n",
    "    for idx, row in zip(x_batch.view(-1),demb.view(-1,demb.shape[-1])):\n",
    "        dC[idx] += row\n",
    "\n",
    "    grads = [dC, dW1, dB1, dW2, dB2, dgamma, dbeta]\n",
    "    \n",
    "\n",
    "    # step learning rate decay\n",
    "    #lr = 0.1 if i < 100000 else 0.01\n",
    "    lr = 0.003\n",
    "    # Update the parameters using torch's autograd\n",
    "    for p, grad in zip(parameters, grads):\n",
    "        #p.data -= p.grad * lr # using autograd's gradient\n",
    "        p.data -= grad * lr # our manual gradient\n",
    "    \n",
    "    # track stats\n",
    "    if i % 10000 == 0:\n",
    "        print(f\"Step {i/steps*100:.2f}%\", loss.item())\n",
    "    lossi.append(loss.log10().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 10)       : Exact: False, Approx: True , Max diff: 2.2351741790771484e-08\n",
      "(30, 64)       : Exact: False, Approx: True , Max diff: 1.1175870895385742e-08\n",
      "(1, 64)        : Exact: False, Approx: True , Max diff: 4.6566128730773926e-09\n",
      "(64, 27)       : Exact: False, Approx: True , Max diff: 2.2351741790771484e-08\n",
      "(27,)          : Exact: False, Approx: True , Max diff: 7.450580596923828e-09\n",
      "(1, 64)        : Exact: False, Approx: True , Max diff: 5.587935447692871e-09\n",
      "(1, 64)        : Exact: False, Approx: True , Max diff: 6.51925802230835e-09\n"
     ]
    }
   ],
   "source": [
    "# make sure that the our gradients match pytorch's autograd\n",
    "for p, grad in zip(parameters, grads):\n",
    "    cmp(str(tuple(p.shape)), grad, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calbirate the abtch norm at the end of the training\n",
    "with torch.no_grad():\n",
    "    # pass the entire training set through the network\n",
    "    emb = C[x_train].view(-1, block_size*n_embed)\n",
    "    z1 = emb @ W1 + B1\n",
    "    # compute the mean and std of the logits\n",
    "    z1_mean = z1.mean(dim=0, keepdim=True)\n",
    "    z1_std = z1.std(dim=0, keepdim=True)\n",
    "\n",
    "z1_mean.shape, z1_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.155775547027588\n",
      "val loss: 2.1701865196228027\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad() # this disables gradient computation, saves memory, and speeds up computation for the following function\n",
    "def evaluate(split):\n",
    "    x, y = {\n",
    "        'train': (x_train, y_train),\n",
    "        'val': (x_val, y_val),\n",
    "        'test': (x_test, y_test)\n",
    "    }[split]\n",
    "    emb = C[x].view(-1, block_size*n_embed)\n",
    "    z1 = emb @ W1 + B1\n",
    "    ## batch normalization\n",
    "    z1_standardized = (z1 - z1_mean) / z1_std\n",
    "    z1_rescaled = z1_standardized * gamma + beta\n",
    "    a1 = torch.tanh(z1_rescaled)\n",
    "    z2 = a1 @ W2 + B2\n",
    "    loss = F.cross_entropy(z2, y)\n",
    "    print(split, 'loss:', loss.item())\n",
    "\n",
    "evaluate('train')\n",
    "evaluate('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jhyla\n",
      "owanedk\n",
      "lacer\n",
      "kiyah\n",
      "kylani\n",
      "laj\n",
      "jadylina\n",
      "mai\n",
      "ar\n",
      "aly\n",
      "alandrey\n",
      "alus\n",
      "walliouofben\n",
      "sai\n",
      "leva\n",
      "brynni\n",
      "sanikoi\n",
      "lelyn\n",
      "alis\n",
      "ello\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647 + 4)\n",
    "\n",
    "for _ in range(20):\n",
    "    out = []\n",
    "    context = [0] * block_size # we start with the '.' index, block_size times\n",
    "    while True:\n",
    "        emb = C[context].view(1, -1)\n",
    "        z1 = emb @ W1 + B1\n",
    "        z1_standardized = (z1 - z1_mean) / z1_std\n",
    "        z1_rescaled = z1_standardized * gamma + beta\n",
    "        a1 = torch.tanh(z1_rescaled)\n",
    "        z2 = a1 @ W2 + B2\n",
    "        probs = F.softmax(z2, dim=1)\n",
    "        next_char = torch.multinomial(probs.view(-1), 1, generator=g).item()\n",
    "        if next_char == 0:\n",
    "            break\n",
    "        out.append(next_char)\n",
    "\n",
    "        context = context[1:] + [next_char]\n",
    "    print(''.join(itos[i] for i in out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
